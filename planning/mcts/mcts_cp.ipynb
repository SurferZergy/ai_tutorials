{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a4aba9",
   "metadata": {},
   "source": [
    "Monte Carlo Tree Search (MCTS) is best known for adversarial planning in two-player zero-sum games, but it is not limited to that and can be applied to any decision-making process.\n",
    "\n",
    "In the CartPole environment, we face a continuous state space and a discrete action space. MCTS requires discrete states; otherwise, we would have an infinite number of leaves. To address this, we will bin the state space to discretize it.\n",
    "\n",
    "For simulating rollouts, we will use the gym environment itself. CartPole is simple enough that we can take a Python deepcopy and simulate the rollout using random or chosen actions. The original environment remains unchanged until a real, non-simulated action is applied to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4565c6",
   "metadata": {},
   "source": [
    "### Discretize to 10 bins, then perform MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bdcf451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02977553  0.02695098 -0.03981876  0.03226086]\n",
      "r 38.0\n",
      "children [<__main__.MCTSNode object at 0x7f031fe1fdf0>, <__main__.MCTSNode object at 0x7f031fe1f9a0>]\n",
      "0.0\n",
      "0.0\n",
      "mv 0.0\n",
      "bst 0.0\n",
      "curr 38.0\n",
      "action 0\n",
      "r 33.0\n",
      "children [<__main__.MCTSNode object at 0x7f031fe1f5b0>, <__main__.MCTSNode object at 0x7f031fe1f130>]\n",
      "0.0\n",
      "33.0\n",
      "mv 33.0\n",
      "bst 33.0\n",
      "curr 33.0\n",
      "action 1\n",
      "r 19.0\n",
      "children [<__main__.MCTSNode object at 0x7f031fe1faf0>, <__main__.MCTSNode object at 0x7f031fe1f160>]\n",
      "52.0\n",
      "0.0\n",
      "mv 52.0\n",
      "bst 0.0\n",
      "curr 52.0\n",
      "action 0\n",
      "r 26.0\n",
      "children [<__main__.MCTSNode object at 0x7f03327cc550>, <__main__.MCTSNode object at 0x7f031fe1f9d0>]\n",
      "26.0\n",
      "52.0\n",
      "mv 52.0\n",
      "bst 26.0\n",
      "curr 78.0\n",
      "action 1\n",
      "r 18.0\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7f031fb36b50>, <__main__.MCTSNode object at 0x7f031fb36d00>]\n",
      "55.0\n",
      "19.0\n",
      "mv 55.0\n",
      "bst 19.0\n",
      "curr 74.0\n",
      "action 0\n",
      "r 21.0\n",
      "children [<__main__.MCTSNode object at 0x7f031fb36f10>, <__main__.MCTSNode object at 0x7f031fb36ca0>]\n",
      "0.0\n",
      "76.0\n",
      "mv 76.0\n",
      "bst 0.0\n",
      "curr 76.0\n",
      "action 1\n",
      "r 33.0\n",
      "r 8.0\n",
      "children [<__main__.MCTSNode object at 0x7f031fb14fd0>, <__main__.MCTSNode object at 0x7f031fb230a0>]\n",
      "8.0\n",
      "109.0\n",
      "mv 109.0\n",
      "bst 109.0\n",
      "curr 117.0\n",
      "action 1\n",
      "r 14.0\n",
      "children [<__main__.MCTSNode object at 0x7f03240ca6a0>, <__main__.MCTSNode object at 0x7f03240ca730>]\n",
      "72.0\n",
      "51.0\n",
      "mv 72.0\n",
      "bst 51.0\n",
      "curr 123.0\n",
      "action 0\n",
      "r 22.0\n",
      "children [<__main__.MCTSNode object at 0x7f03240ae430>, <__main__.MCTSNode object at 0x7f03240ae100>]\n",
      "21.0\n",
      "73.0\n",
      "mv 73.0\n",
      "bst 21.0\n",
      "curr 94.0\n",
      "action 1\n",
      "r 32.0\n",
      "children [<__main__.MCTSNode object at 0x7f03242e7cd0>, <__main__.MCTSNode object at 0x7f03242e7a60>]\n",
      "73.0\n",
      "32.0\n",
      "mv 73.0\n",
      "bst 32.0\n",
      "curr 105.0\n",
      "action 0\n",
      "r 17.0\n",
      "children [<__main__.MCTSNode object at 0x7f03242b1160>, <__main__.MCTSNode object at 0x7f031fe1fa00>]\n",
      "51.0\n",
      "39.0\n",
      "mv 51.0\n",
      "bst 51.0\n",
      "curr 90.0\n",
      "action 0\n",
      "r 47.0\n",
      "children [<__main__.MCTSNode object at 0x7f03242b1610>, <__main__.MCTSNode object at 0x7f03242b16a0>]\n",
      "0.0\n",
      "98.0\n",
      "mv 98.0\n",
      "bst 0.0\n",
      "curr 98.0\n",
      "action 1\n",
      "r 15.0\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7f0324139970>, <__main__.MCTSNode object at 0x7f0324139be0>]\n",
      "40.0\n",
      "80.0\n",
      "mv 80.0\n",
      "bst 80.0\n",
      "curr 120.0\n",
      "action 1\n",
      "r 18.0\n",
      "r 39.0\n",
      "children [<__main__.MCTSNode object at 0x7f03246148e0>, <__main__.MCTSNode object at 0x7f0324614970>]\n",
      "90.0\n",
      "47.0\n",
      "mv 90.0\n",
      "bst 47.0\n",
      "curr 137.0\n",
      "action 0\n",
      "r 21.0\n",
      "children [<__main__.MCTSNode object at 0x7f0324543070>, <__main__.MCTSNode object at 0x7f03244f4cd0>]\n",
      "36.0\n",
      "57.0\n",
      "mv 57.0\n",
      "bst 36.0\n",
      "curr 111.0\n",
      "action 1\n",
      "r 11.0\n",
      "children [<__main__.MCTSNode object at 0x7f032453dd90>, <__main__.MCTSNode object at 0x7f03244f4e50>]\n",
      "68.0\n",
      "0.0\n",
      "mv 68.0\n",
      "bst 68.0\n",
      "curr 68.0\n",
      "action 0\n",
      "r 13.0\n",
      "children [<__main__.MCTSNode object at 0x7f032453dbb0>, <__main__.MCTSNode object at 0x7f032453dd30>]\n",
      "11.0\n",
      "70.0\n",
      "mv 70.0\n",
      "bst 70.0\n",
      "curr 81.0\n",
      "action 1\n",
      "r 10.0\n",
      "r 30.0\n",
      "children [<__main__.MCTSNode object at 0x7f032453d820>, <__main__.MCTSNode object at 0x7f032453de80>]\n",
      "80.0\n",
      "30.0\n",
      "mv 80.0\n",
      "bst 30.0\n",
      "curr 110.0\n",
      "action 0\n",
      "r 10.0\n",
      "children [<__main__.MCTSNode object at 0x7f0324543670>, <__main__.MCTSNode object at 0x7f0324531070>]\n",
      "70.0\n",
      "20.0\n",
      "mv 70.0\n",
      "bst 20.0\n",
      "curr 90.0\n",
      "action 0\n",
      "r 12.0\n",
      "children [<__main__.MCTSNode object at 0x7f032454f1f0>, <__main__.MCTSNode object at 0x7f03245433a0>]\n",
      "82.0\n",
      "0.0\n",
      "mv 82.0\n",
      "bst 0.0\n",
      "curr 82.0\n",
      "action 0\n",
      "r 22.0\n",
      "children [<__main__.MCTSNode object at 0x7f03242ff550>, <__main__.MCTSNode object at 0x7f03242ff5e0>]\n",
      "0.0\n",
      "104.0\n",
      "mv 104.0\n",
      "bst 104.0\n",
      "curr 104.0\n",
      "action 1\n",
      "r 15.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f799670>, <__main__.MCTSNode object at 0x7f031f799910>]\n",
      "15.0\n",
      "104.0\n",
      "mv 104.0\n",
      "bst 104.0\n",
      "curr 119.0\n",
      "action 1\n",
      "r 15.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f6d1190>, <__main__.MCTSNode object at 0x7f031f7da640>]\n",
      "0.0\n",
      "101.0\n",
      "mv 101.0\n",
      "bst 0.0\n",
      "curr 119.0\n",
      "action 1\n",
      "r 32.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f5c08b0>, <__main__.MCTSNode object at 0x7f031f6d1400>]\n",
      "34.0\n",
      "99.0\n",
      "mv 99.0\n",
      "bst 34.0\n",
      "curr 133.0\n",
      "action 1\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f5c0f40>, <__main__.MCTSNode object at 0x7f031f5c0c10>]\n",
      "39.0\n",
      "67.0\n",
      "mv 67.0\n",
      "bst 39.0\n",
      "curr 106.0\n",
      "action 1\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f5c9370>, <__main__.MCTSNode object at 0x7f031f5c9790>]\n",
      "0.0\n",
      "74.0\n",
      "mv 74.0\n",
      "bst 74.0\n",
      "curr 74.0\n",
      "action 1\n",
      "r 3.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f5c9b80>, <__main__.MCTSNode object at 0x7f031f5c9e20>]\n",
      "70.0\n",
      "7.0\n",
      "mv 70.0\n",
      "bst 70.0\n",
      "curr 77.0\n",
      "action 0\n",
      "r 3.0\n",
      "r 21.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f5d41c0>, <__main__.MCTSNode object at 0x7f031f5d4340>]\n",
      "10.0\n",
      "84.0\n",
      "mv 84.0\n",
      "bst 84.0\n",
      "curr 94.0\n",
      "action 1\n",
      "r 2.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f56e100>, <__main__.MCTSNode object at 0x7f031f56ef10>]\n",
      "15.0\n",
      "71.0\n",
      "mv 71.0\n",
      "bst 15.0\n",
      "curr 86.0\n",
      "action 1\n",
      "r 1.0\n",
      "children [<__main__.MCTSNode object at 0x7f031f3267f0>, <__main__.MCTSNode object at 0x7f031f434100>]\n",
      "18.0\n",
      "54.0\n",
      "mv 54.0\n",
      "bst 54.0\n",
      "curr 72.0\n",
      "action 1\n",
      "done\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import animation\n",
    "\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None, action=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.action = action\n",
    "        self.visits = 0\n",
    "        self.wins = 0\n",
    "\n",
    "    def is_fully_expanded(self, action_space_size):\n",
    "        return len(self.children) == action_space_size\n",
    "\n",
    "    def best_child(self, exploration_param=1.414):\n",
    "        choices_weights = [\n",
    "            (child.wins / max(1, child.visits)) + exploration_param * math.sqrt(\n",
    "                math.log(max(1, self.visits)) / max(1, child.visits)\n",
    "            ) for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def most_visited_child(self):\n",
    "        return max(self.children, key=lambda child: child.visits)\n",
    "\n",
    "def discretize_state(state, bins):\n",
    "    \"\"\"\n",
    "    Discretize the continuous state into a discrete bin representation.\n",
    "    We create bins for each feature (position, velocity, angle, angular velocity).\n",
    "    \"\"\"\n",
    "    binned_state = []\n",
    "    for i in range(len(state)):\n",
    "#         print('state[i]', state[i])\n",
    "#         print('bin[i]', bins[i])\n",
    "        binned_state.append(np.digitize(state[i], bins[i]))\n",
    "    return tuple(binned_state)\n",
    "\n",
    "def create_bins():\n",
    "    \"\"\"\n",
    "    Create bins for each state variable.\n",
    "    CartPole has 4 continuous state variables:\n",
    "    [Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity].\n",
    "    We define the ranges and bins for each.\n",
    "    \"\"\"\n",
    "    bins = [\n",
    "        np.linspace(-4.8, 4.8, 10),  # Cart Position\n",
    "        np.linspace(-5.0, 5.0, 10),  # Cart Velocity\n",
    "        np.linspace(-0.418, 0.418, 10),  # Pole Angle\n",
    "        np.linspace(-5.0, 5.0, 10),  # Pole Angular Velocity\n",
    "    ]\n",
    "    return bins\n",
    "\n",
    "def rollout(env, bins):\n",
    "    \"\"\"\n",
    "    Simulate a random rollout from the current state.\n",
    "    \"\"\"\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Randomly pick an action (exploration)\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def backpropagate(node, reward):\n",
    "    while node is not None:\n",
    "        node.visits += 1\n",
    "        node.wins += reward\n",
    "        node = node.parent\n",
    "\n",
    "def expand(node, env, action_space_size, bins):\n",
    "    \"\"\"\n",
    "    Expand the node by creating child nodes for each action.\n",
    "    \"\"\"\n",
    "    for action in range(action_space_size):\n",
    "        # Clone the environment and step with the current action\n",
    "        env_copy = gym.make('CartPole-v1')\n",
    "        env_copy.reset()\n",
    "        env_copy.env.state = env.env.state  # Copy the environment state\n",
    "        state, reward, done, _, _ = env_copy.step(action)\n",
    "\n",
    "        # Discretize the state to get the discrete representation\n",
    "        discrete_state = discretize_state(state, bins)\n",
    "\n",
    "        child_node = MCTSNode(state=discrete_state, parent=node, action=action)\n",
    "        node.children.append(child_node)\n",
    "\n",
    "def select(node, action_space_size):\n",
    "    \"\"\"\n",
    "    Traverse the tree by selecting the best child node based on the UCB1 algorithm.\n",
    "    \"\"\"\n",
    "    current_node = node\n",
    "    while current_node.is_fully_expanded(action_space_size):\n",
    "        current_node = current_node.best_child()\n",
    "    return current_node\n",
    "\n",
    "def mcts(env, state, current_node, simulations=1000):\n",
    "    env_copy = copy.deepcopy(env)\n",
    "    action_space_size = env.action_space.n\n",
    "\n",
    "    for _ in range(simulations):\n",
    "        # Step 1: Selection\n",
    "        selected_node = select(current_node, action_space_size)\n",
    "#         print('sn',selected_node)\n",
    "        \n",
    "        # Step 2: Expansion\n",
    "        expand(selected_node, env_copy, action_space_size, bins)\n",
    "        \n",
    "        # Step 3: Simulation\n",
    "        reward = rollout(env_copy, bins)\n",
    "        if reward !=0:\n",
    "            print('r', reward)\n",
    "        \n",
    "        # Step 4: Backpropagation\n",
    "        backpropagate(selected_node, reward)\n",
    "        \n",
    "    best_node = current_node.best_child(exploration_param=0)\n",
    "    print('children', current_node.children)\n",
    "    for c in current_node.children:\n",
    "        print(c.wins)\n",
    "    print('mv', current_node.most_visited_child().wins)\n",
    "    print('bst', current_node.best_child().wins)\n",
    "    print('curr', current_node.wins)\n",
    "    return best_node\n",
    "\n",
    "# Initialize the CartPole environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Run MCTS for 1000 simulations\n",
    "\n",
    "\n",
    "# Apply the best move (select action based on the best child)\n",
    "state = env.reset()[0]\n",
    "print(state)\n",
    "done = False\n",
    "tot_r = 0\n",
    "\n",
    "# Discretize the initial state\n",
    "bins = create_bins()\n",
    "discrete_state = discretize_state(state, bins)\n",
    "current_node = MCTSNode(discrete_state) # first will be root node\n",
    "\n",
    "while not done:\n",
    "    current_node = mcts(env, state, current_node, simulations=1000)\n",
    "    print('action', current_node.action)\n",
    "    state, reward, done, _, _ = env.step(current_node.action)\n",
    "    tot_r += reward\n",
    "    #     print(reward)\n",
    "    env.render()\n",
    "\n",
    "print('done')\n",
    "print(tot_r)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6630b18",
   "metadata": {},
   "source": [
    "### This code block we try 100 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d6708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 0\n",
      "action 1\n",
      "action 1\n",
      "action 0\n",
      "action 1\n",
      "action 0\n",
      "action 1\n",
      "action 1\n",
      "action 1\n",
      "action 1\n",
      "action 1\n",
      "action 1\n",
      "action 1\n",
      "action 1\n",
      "action 0\n",
      "done\n",
      "15.0\n"
     ]
    }
   ],
   "source": [
    "#100 bins\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import animation\n",
    "\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None, action=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.action = action\n",
    "        self.visits = 0\n",
    "        self.wins = 0\n",
    "\n",
    "    def is_fully_expanded(self, action_space_size):\n",
    "        return len(self.children) == action_space_size\n",
    "\n",
    "    def best_child(self, exploration_param=1.414):\n",
    "        choices_weights = [\n",
    "            (child.wins / max(1, child.visits)) + exploration_param * math.sqrt(\n",
    "                math.log(max(1, self.visits)) / max(1, child.visits)\n",
    "            ) for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def most_visited_child(self):\n",
    "        return max(self.children, key=lambda child: child.visits)\n",
    "\n",
    "def discretize_state(state, bins):\n",
    "    \"\"\"\n",
    "    Discretize the continuous state into a discrete bin representation.\n",
    "    We create bins for each feature (position, velocity, angle, angular velocity).\n",
    "    \"\"\"\n",
    "    binned_state = []\n",
    "    for i in range(len(state)):\n",
    "#         print('state[i]', state[i])\n",
    "#         print('bin[i]', bins[i])\n",
    "        binned_state.append(np.digitize(state[i], bins[i]))\n",
    "    return tuple(binned_state)\n",
    "\n",
    "def create_bins():\n",
    "    \"\"\"\n",
    "    Create bins for each state variable.\n",
    "    CartPole has 4 continuous state variables:\n",
    "    [Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity].\n",
    "    We define the ranges and bins for each.\n",
    "    \"\"\"\n",
    "    bins = [\n",
    "        np.linspace(-4.8, 4.8, 100),  # Cart Position\n",
    "        np.linspace(-5.0, 5.0, 100),  # Cart Velocity\n",
    "        np.linspace(-0.418, 0.418, 100),  # Pole Angle\n",
    "        np.linspace(-5.0, 5.0, 100),  # Pole Angular Velocity\n",
    "    ]\n",
    "    return bins\n",
    "\n",
    "def rollout(env, bins):\n",
    "    \"\"\"\n",
    "    Simulate a random rollout from the current state.\n",
    "    \"\"\"\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Randomly pick an action (exploration)\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def backpropagate(node, reward):\n",
    "    while node is not None:\n",
    "        node.visits += 1\n",
    "        node.wins += reward\n",
    "        node = node.parent\n",
    "\n",
    "def expand(node, env, action_space_size, bins):\n",
    "    \"\"\"\n",
    "    Expand the node by creating child nodes for each action.\n",
    "    \"\"\"\n",
    "    for action in range(action_space_size):\n",
    "        # Clone the environment and step with the current action\n",
    "        env_copy = gym.make('CartPole-v1')\n",
    "        env_copy.reset()\n",
    "        env_copy.env.state = env.env.state  # Copy the environment state\n",
    "        state, reward, done, _, _ = env_copy.step(action)\n",
    "\n",
    "        # Discretize the state to get the discrete representation\n",
    "        discrete_state = discretize_state(state, bins)\n",
    "\n",
    "        child_node = MCTSNode(state=discrete_state, parent=node, action=action)\n",
    "        node.children.append(child_node)\n",
    "\n",
    "def select(node, action_space_size):\n",
    "    \"\"\"\n",
    "    Traverse the tree by selecting the best child node based on the UCB1 algorithm.\n",
    "    \"\"\"\n",
    "    current_node = node\n",
    "    while current_node.is_fully_expanded(action_space_size):\n",
    "        current_node = current_node.best_child()\n",
    "    return current_node\n",
    "\n",
    "def mcts(env, state, current_node, simulations=1000):\n",
    "    env_copy = copy.deepcopy(env)\n",
    "    action_space_size = env.action_space.n\n",
    "\n",
    "    for _ in range(simulations):\n",
    "        # Step 1: Selection\n",
    "        selected_node = select(current_node, action_space_size)\n",
    "#         print('sn',selected_node)\n",
    "        \n",
    "        # Step 2: Expansion\n",
    "        expand(selected_node, env_copy, action_space_size, bins)\n",
    "        \n",
    "        # Step 3: Simulation\n",
    "        reward = rollout(env_copy, bins)\n",
    "        \n",
    "        # Step 4: Backpropagation\n",
    "        backpropagate(selected_node, reward)\n",
    "        \n",
    "    best_node = current_node.best_child(exploration_param=0)\n",
    "\n",
    "    return best_node\n",
    "\n",
    "# Initialize the CartPole environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Run MCTS for 1000 simulations\n",
    "\n",
    "\n",
    "# Apply the best move (select action based on the best child)\n",
    "state = env.reset()[0]\n",
    "done = False\n",
    "tot_r = 0\n",
    "\n",
    "# Discretize the initial state\n",
    "bins = create_bins()\n",
    "discrete_state = discretize_state(state, bins)\n",
    "current_node = MCTSNode(discrete_state) # first will be root node\n",
    "\n",
    "while not done:\n",
    "    current_node = mcts(env, state, current_node, simulations=1000)\n",
    "    print('action', current_node.action)\n",
    "    state, reward, done, _, _ = env.step(current_node.action)\n",
    "    tot_r += reward\n",
    "    env.render()\n",
    "\n",
    "print('done')\n",
    "print(tot_r)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa6039",
   "metadata": {},
   "source": [
    "we learn that 10 and 100 bins are somewhat similar, so it doens't really matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c827ee06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c2677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
