{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b1c0350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/n_mbpo/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.state to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.state` for environment variables or `env.get_wrapper_attr('state')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/james/miniconda3/envs/n_mbpo/lib/python3.9/site-packages/gymnasium/envs/classic_control/cartpole.py:180: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 15.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122ae6d0>, <__main__.MCTSNode object at 0x7fce122ae670>]\n",
      "0.0\n",
      "0.0\n",
      "mv 0.0\n",
      "bst 0.0\n",
      "curr 15.0\n",
      "action 0\n",
      "r 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/n_mbpo/lib/python3.9/site-packages/gymnasium/envs/classic_control/cartpole.py:215: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children [<__main__.MCTSNode object at 0x7fce122ae850>, <__main__.MCTSNode object at 0x7fce122ae6a0>]\n",
      "0.0\n",
      "30.0\n",
      "mv 30.0\n",
      "bst 30.0\n",
      "curr 30.0\n",
      "action 1\n",
      "r 17.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122ae640>, <__main__.MCTSNode object at 0x7fce122aeb50>]\n",
      "47.0\n",
      "0.0\n",
      "mv 47.0\n",
      "bst 0.0\n",
      "curr 47.0\n",
      "action 0\n",
      "r 29.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122ae220>, <__main__.MCTSNode object at 0x7fce122aec10>]\n",
      "29.0\n",
      "47.0\n",
      "mv 47.0\n",
      "bst 47.0\n",
      "curr 76.0\n",
      "action 1\n",
      "r 17.0\n",
      "r 21.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122bf040>, <__main__.MCTSNode object at 0x7fce122bf310>]\n",
      "85.0\n",
      "0.0\n",
      "mv 85.0\n",
      "bst 85.0\n",
      "curr 85.0\n",
      "action 0\n",
      "r 9.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122bf5b0>, <__main__.MCTSNode object at 0x7fce122bf640>]\n",
      "55.0\n",
      "39.0\n",
      "mv 55.0\n",
      "bst 39.0\n",
      "curr 94.0\n",
      "action 0\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122bfbb0>, <__main__.MCTSNode object at 0x7fce122bfc40>]\n",
      "28.0\n",
      "34.0\n",
      "mv 34.0\n",
      "bst 28.0\n",
      "curr 62.0\n",
      "action 1\n",
      "r 11.0\n",
      "children [<__main__.MCTSNode object at 0x7fce12289b20>, <__main__.MCTSNode object at 0x7fce12289bb0>]\n",
      "0.0\n",
      "45.0\n",
      "mv 45.0\n",
      "bst 0.0\n",
      "curr 45.0\n",
      "action 1\n",
      "r 6.0\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7fce121e75b0>, <__main__.MCTSNode object at 0x7fce121e7640>]\n",
      "51.0\n",
      "4.0\n",
      "mv 51.0\n",
      "bst 51.0\n",
      "curr 55.0\n",
      "action 0\n",
      "r 9.0\n",
      "children [<__main__.MCTSNode object at 0x7fce12206670>, <__main__.MCTSNode object at 0x7fce12206700>]\n",
      "6.0\n",
      "54.0\n",
      "mv 54.0\n",
      "bst 54.0\n",
      "curr 60.0\n",
      "action 1\n",
      "r 26.0\n",
      "children [<__main__.MCTSNode object at 0x7fce12179340>, <__main__.MCTSNode object at 0x7fce12179520>]\n",
      "37.0\n",
      "43.0\n",
      "mv 43.0\n",
      "bst 37.0\n",
      "curr 80.0\n",
      "action 1\n",
      "r 27.0\n",
      "r 20.0\n",
      "children [<__main__.MCTSNode object at 0x7fce120c9820>, <__main__.MCTSNode object at 0x7fce121d09d0>]\n",
      "73.0\n",
      "0.0\n",
      "mv 73.0\n",
      "bst 73.0\n",
      "curr 90.0\n",
      "action 0\n",
      "r 11.0\n",
      "r 3.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122ae4c0>, <__main__.MCTSNode object at 0x7fce120bcfa0>]\n",
      "37.0\n",
      "50.0\n",
      "mv 50.0\n",
      "bst 50.0\n",
      "curr 87.0\n",
      "action 1\n",
      "r 10.0\n",
      "children [<__main__.MCTSNode object at 0x7fce120c9910>, <__main__.MCTSNode object at 0x7fce121d0d90>]\n",
      "3.0\n",
      "57.0\n",
      "mv 57.0\n",
      "bst 57.0\n",
      "curr 60.0\n",
      "action 1\n",
      "r 15.0\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7fce120c99d0>, <__main__.MCTSNode object at 0x7fce120c9a90>]\n",
      "19.0\n",
      "57.0\n",
      "mv 57.0\n",
      "bst 57.0\n",
      "curr 76.0\n",
      "action 1\n",
      "r 16.0\n",
      "children [<__main__.MCTSNode object at 0x7fce12084c70>, <__main__.MCTSNode object at 0x7fce12084be0>]\n",
      "47.0\n",
      "26.0\n",
      "mv 47.0\n",
      "bst 47.0\n",
      "curr 73.0\n",
      "action 0\n",
      "r 8.0\n",
      "children [<__main__.MCTSNode object at 0x7fce11fa9730>, <__main__.MCTSNode object at 0x7fce11fa97c0>]\n",
      "55.0\n",
      "0.0\n",
      "mv 55.0\n",
      "bst 55.0\n",
      "curr 55.0\n",
      "action 0\n",
      "r 73.0\n",
      "children [<__main__.MCTSNode object at 0x7fce11ec1280>, <__main__.MCTSNode object at 0x7fce11ec1520>]\n",
      "120.0\n",
      "8.0\n",
      "mv 120.0\n",
      "bst 120.0\n",
      "curr 128.0\n",
      "action 0\n",
      "r 8.0\n",
      "children [<__main__.MCTSNode object at 0x7fce11d2fb20>, <__main__.MCTSNode object at 0x7fce11d2fbb0>]\n",
      "0.0\n",
      "128.0\n",
      "mv 128.0\n",
      "bst 128.0\n",
      "curr 128.0\n",
      "action 1\n",
      "r 8.0\n",
      "children [<__main__.MCTSNode object at 0x7fce1196c760>, <__main__.MCTSNode object at 0x7fce1196c7f0>]\n",
      "81.0\n",
      "55.0\n",
      "mv 81.0\n",
      "bst 81.0\n",
      "curr 136.0\n",
      "action 0\n",
      "r 5.0\n",
      "children [<__main__.MCTSNode object at 0x7fce1195b430>, <__main__.MCTSNode object at 0x7fce1195bf10>]\n",
      "5.0\n",
      "81.0\n",
      "mv 81.0\n",
      "bst 5.0\n",
      "curr 86.0\n",
      "action 1\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7fce117ff310>, <__main__.MCTSNode object at 0x7fce117ff190>]\n",
      "88.0\n",
      "0.0\n",
      "mv 88.0\n",
      "bst 0.0\n",
      "curr 88.0\n",
      "action 0\n",
      "r 5.0\n",
      "children [<__main__.MCTSNode object at 0x7fce117ff760>, <__main__.MCTSNode object at 0x7fce117ff7f0>]\n",
      "78.0\n",
      "15.0\n",
      "mv 78.0\n",
      "bst 15.0\n",
      "curr 93.0\n",
      "action 0\n",
      "r 3.0\n",
      "children [<__main__.MCTSNode object at 0x7fce117ffeb0>, <__main__.MCTSNode object at 0x7fce117ff2b0>]\n",
      "3.0\n",
      "78.0\n",
      "mv 78.0\n",
      "bst 3.0\n",
      "curr 81.0\n",
      "action 1\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7fce11673df0>, <__main__.MCTSNode object at 0x7fce11673e80>]\n",
      "0.0\n",
      "82.0\n",
      "mv 82.0\n",
      "bst 82.0\n",
      "curr 82.0\n",
      "action 1\n",
      "r 3.0\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7fce1148f6a0>, <__main__.MCTSNode object at 0x7fce1148f730>]\n",
      "7.0\n",
      "82.0\n",
      "mv 82.0\n",
      "bst 82.0\n",
      "curr 89.0\n",
      "action 1\n",
      "r 2.0\n",
      "r 5.0\n",
      "children [<__main__.MCTSNode object at 0x7fce112d43a0>, <__main__.MCTSNode object at 0x7fce112d44f0>]\n",
      "89.0\n",
      "0.0\n",
      "mv 89.0\n",
      "bst 0.0\n",
      "curr 89.0\n",
      "action 0\n",
      "r 1.0\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7fce1133ca90>, <__main__.MCTSNode object at 0x7fce115e2640>]\n",
      "16.0\n",
      "8.0\n",
      "mv 16.0\n",
      "bst 16.0\n",
      "curr 97.0\n",
      "action 0\n",
      "done\n",
      "28.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import animation\n",
    "\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None, action=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.action = action\n",
    "        self.visits = 0\n",
    "        self.wins = 0\n",
    "\n",
    "    def is_fully_expanded(self, action_space_size):\n",
    "        return len(self.children) == action_space_size\n",
    "\n",
    "    def best_child(self, exploration_param=1.414):\n",
    "        choices_weights = [\n",
    "            (child.wins / max(1, child.visits)) + exploration_param * math.sqrt(\n",
    "                math.log(max(1, self.visits)) / max(1, child.visits)\n",
    "            ) for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def most_visited_child(self):\n",
    "        return max(self.children, key=lambda child: child.visits)\n",
    "\n",
    "def discretize_state(state, bins):\n",
    "    \"\"\"\n",
    "    Discretize the continuous state into a discrete bin representation.\n",
    "    We create bins for each feature (position, velocity, angle, angular velocity).\n",
    "    \"\"\"\n",
    "    binned_state = []\n",
    "    for i in range(len(state)):\n",
    "#         print('state[i]', state[i])\n",
    "#         print('bin[i]', bins[i])\n",
    "        binned_state.append(np.digitize(state[i], bins[i]))\n",
    "    return tuple(binned_state)\n",
    "\n",
    "def create_bins():\n",
    "    \"\"\"\n",
    "    Create bins for each state variable.\n",
    "    CartPole has 4 continuous state variables:\n",
    "    [Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity].\n",
    "    We define the ranges and bins for each.\n",
    "    \"\"\"\n",
    "    bins = [\n",
    "        np.linspace(-4.8, 4.8, 10),  # Cart Position\n",
    "        np.linspace(-5.0, 5.0, 10),  # Cart Velocity\n",
    "        np.linspace(-0.418, 0.418, 10),  # Pole Angle\n",
    "        np.linspace(-5.0, 5.0, 10),  # Pole Angular Velocity\n",
    "    ]\n",
    "    return bins\n",
    "\n",
    "def rollout(env, bins):\n",
    "    \"\"\"\n",
    "    Simulate a random rollout from the current state.\n",
    "    \"\"\"\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Randomly pick an action (exploration)\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def backpropagate(node, reward):\n",
    "    while node is not None:\n",
    "        node.visits += 1\n",
    "        node.wins += reward\n",
    "        node = node.parent\n",
    "\n",
    "def expand(node, env, action_space_size, bins):\n",
    "    \"\"\"\n",
    "    Expand the node by creating child nodes for each action.\n",
    "    \"\"\"\n",
    "    for action in range(action_space_size):\n",
    "        # Clone the environment and step with the current action\n",
    "        env_copy = gym.make('CartPole-v1')\n",
    "        env_copy.reset()\n",
    "        env_copy.env.state = env.env.state  # Copy the environment state\n",
    "        state, reward, done, _, _ = env_copy.step(action)\n",
    "\n",
    "        # Discretize the state to get the discrete representation\n",
    "        discrete_state = discretize_state(state, bins)\n",
    "\n",
    "        child_node = MCTSNode(state=discrete_state, parent=node, action=action)\n",
    "        node.children.append(child_node)\n",
    "\n",
    "def select(node, action_space_size):\n",
    "    \"\"\"\n",
    "    Traverse the tree by selecting the best child node based on the UCB1 algorithm.\n",
    "    \"\"\"\n",
    "    current_node = node\n",
    "    while current_node.is_fully_expanded(action_space_size):\n",
    "        current_node = current_node.best_child()\n",
    "    return current_node\n",
    "\n",
    "def mcts(env, state, current_node, simulations=1000):\n",
    "    env_copy = copy.deepcopy(env)\n",
    "    action_space_size = env.action_space.n\n",
    "\n",
    "    for _ in range(simulations):\n",
    "        # Step 1: Selection\n",
    "        selected_node = select(current_node, action_space_size)\n",
    "#         print('sn',selected_node)\n",
    "        \n",
    "        # Step 2: Expansion\n",
    "        expand(selected_node, env_copy, action_space_size, bins)\n",
    "        \n",
    "        # Step 3: Simulation\n",
    "        reward = rollout(env_copy, bins)\n",
    "        if reward !=0:\n",
    "            print('r', reward)\n",
    "        \n",
    "        # Step 4: Backpropagation\n",
    "        backpropagate(selected_node, reward)\n",
    "        \n",
    "    best_node = current_node.best_child(exploration_param=0)\n",
    "    print('children', current_node.children)\n",
    "    for c in current_node.children:\n",
    "        print(c.wins)\n",
    "    print('mv', current_node.most_visited_child().wins)\n",
    "    print('bst', current_node.best_child().wins)\n",
    "    print('curr', current_node.wins)\n",
    "    return best_node\n",
    "\n",
    "# Initialize the CartPole environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Run MCTS for 1000 simulations\n",
    "\n",
    "\n",
    "# Apply the best move (select action based on the best child)\n",
    "env.reset()\n",
    "done = False\n",
    "tot_r = 0\n",
    "\n",
    "# Discretize the initial state\n",
    "bins = create_bins()\n",
    "discrete_state = discretize_state(state, bins)\n",
    "current_node = MCTSNode(discrete_state) # first will be root node\n",
    "\n",
    "while not done:\n",
    "    current_node = mcts(env, state, current_node, simulations=1000)\n",
    "    print('action', current_node.action)\n",
    "    state, reward, done, _, _ = env.step(current_node.action)\n",
    "    tot_r += reward\n",
    "    #     print(reward)\n",
    "    env.render()\n",
    "\n",
    "print('done')\n",
    "print(tot_r)\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:n_mbpo] *",
   "language": "python",
   "name": "conda-env-n_mbpo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
