{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27df933",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'action_space'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce74e2fb7312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ce74e2fb7312>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_simulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# Choose the best action from the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ce74e2fb7312>\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(root, num_simulations)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_expanded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ce74e2fb7312>\u001b[0m in \u001b[0;36mis_fully_expanded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_fully_expanded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbest_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'action_space'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state  # state of the node\n",
    "        self.parent = parent  # parent node\n",
    "        self.children = []  # child nodes\n",
    "        self.visits = 0  # number of times this node has been visited\n",
    "        self.wins = 0  # total rewards for this node\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) == self.state.action_space.n\n",
    "\n",
    "    def best_child(self, exploration_weight=1.0):\n",
    "        choices_weights = [\n",
    "            (child.wins / child.visits) + exploration_weight * math.sqrt(\n",
    "                (2 * math.log(self.visits) / child.visits) if child.visits > 0 else 0)\n",
    "            for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def expand(self):\n",
    "        unexplored_actions = [a for a in range(self.state.action_space.n) if a not in [child.state.action for child in self.children]]\n",
    "        action = random.choice(unexplored_actions)\n",
    "        next_state, reward, done, _ = self.state.step(action)\n",
    "        child_node = Node(next_state, parent=self)\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "    def update(self, reward):\n",
    "        self.visits += 1\n",
    "        self.wins += reward\n",
    "\n",
    "\n",
    "def mcts(root, num_simulations):\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        # Selection\n",
    "        while node.is_fully_expanded() and node.children:\n",
    "            node = node.best_child()\n",
    "\n",
    "        # Expansion\n",
    "        if not node.is_fully_expanded():\n",
    "            node = node.expand()\n",
    "\n",
    "        # Simulation\n",
    "        total_reward = 0\n",
    "        current_state = node.state\n",
    "        while True:\n",
    "            action = current_state.action_space.sample()\n",
    "            next_state, reward, done, _ = current_state.step(action)\n",
    "            total_reward += reward\n",
    "            current_state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Backpropagation\n",
    "        while node is not None:\n",
    "            node.update(total_reward)\n",
    "            node = node.parent\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    state = env.reset()\n",
    "    root = Node(state)\n",
    "    \n",
    "    for episode in range(1000):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            mcts(root, num_simulations=100)\n",
    "\n",
    "            # Choose the best action from the root node\n",
    "            best_action = root.best_child(exploration_weight=0).state.action_space.sample()  # get action based on visits\n",
    "            next_state, reward, done, _ = env.step(best_action)\n",
    "            root = root.best_child()  # move to the best child\n",
    "\n",
    "            if done:\n",
    "                print(f\"Episode {episode} finished!\")\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9efa2340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/n_mbpo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2a05f0f42bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-2a05f0f42bfd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_simulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Choose the best action from the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2a05f0f42bfd>\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(root, num_simulations)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Expansion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_expanded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2a05f0f42bfd>\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0munexplored_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexplored_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mchild_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state  # state of the node\n",
    "        self.parent = parent  # parent node\n",
    "        self.children = []  # child nodes\n",
    "        self.visits = 0  # number of times this node has been visited\n",
    "        self.wins = 0  # total rewards for this node\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) == self.state.action_space.n\n",
    "\n",
    "    def best_child(self, exploration_weight=1.0):\n",
    "        choices_weights = [\n",
    "            (child.wins / child.visits) + exploration_weight * math.sqrt(\n",
    "                (2 * math.log(self.visits) / child.visits) if child.visits > 0 else 0)\n",
    "            for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def expand(self):\n",
    "        unexplored_actions = [a for a in range(self.state.action_space.n) if a not in [child.state.action for child in self.children]]\n",
    "        action = random.choice(unexplored_actions)\n",
    "        next_state, reward, done, _ = self.state.step(action)\n",
    "        child_node = Node(next_state, parent=self)\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "    def update(self, reward):\n",
    "        self.visits += 1\n",
    "        self.wins += reward\n",
    "\n",
    "\n",
    "def mcts(root, num_simulations):\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        # Selection\n",
    "        while node.is_fully_expanded() and node.children:\n",
    "            node = node.best_child()\n",
    "\n",
    "        # Expansion\n",
    "        if not node.is_fully_expanded():\n",
    "            node = node.expand()\n",
    "\n",
    "        # Simulation\n",
    "        total_reward = 0\n",
    "        current_state = node.state\n",
    "        while True:\n",
    "            action = current_state.action_space.sample()  # Sample random action\n",
    "            next_state, reward, done, _ = current_state.step(action)  # Step in the environment\n",
    "            total_reward += reward\n",
    "            current_state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Backpropagation\n",
    "        while node is not None:\n",
    "            node.update(total_reward)\n",
    "            node = node.parent\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    state, _ = env.reset()  # Unpack the reset return value\n",
    "    root = Node(env)\n",
    "\n",
    "    for episode in range(1000):\n",
    "        state, _ = env.reset()  # Reset the environment\n",
    "        root = Node(env)  # Initialize a new root for each episode\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            mcts(root, num_simulations=100)\n",
    "\n",
    "            # Choose the best action from the root node\n",
    "            best_action = root.best_child(exploration_weight=0).children[0].state.action_space.sample()  # get action based on visits\n",
    "            next_state, reward, done, _ = env.step(best_action)\n",
    "            root = root.best_child()  # move to the best child\n",
    "\n",
    "            if done:\n",
    "                print(f\"Episode {episode} finished!\")\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a49ceb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a23ba6456810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-a23ba6456810>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_simulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# Choose the best action from the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a23ba6456810>\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(root, num_simulations)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Expansion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_expanded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a23ba6456810>\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0munexplored_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexplored_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perform the action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mchild_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state  # state of the node\n",
    "        self.parent = parent  # parent node\n",
    "        self.children = []  # child nodes\n",
    "        self.visits = 0  # number of times this node has been visited\n",
    "        self.wins = 0  # total rewards for this node\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) == self.state.action_space.n\n",
    "\n",
    "    def best_child(self, exploration_weight=1.0):\n",
    "        choices_weights = [\n",
    "            (child.wins / child.visits) + exploration_weight * math.sqrt(\n",
    "                (2 * math.log(self.visits) / child.visits) if child.visits > 0 else 0)\n",
    "            for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def expand(self):\n",
    "        unexplored_actions = [a for a in range(self.state.action_space.n) if a not in [child.state.action for child in self.children]]\n",
    "        action = random.choice(unexplored_actions)\n",
    "        next_state, reward, done, _ = self.state.step(action)  # Perform the action\n",
    "        child_node = Node(next_state, parent=self)\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "    def update(self, reward):\n",
    "        self.visits += 1\n",
    "        self.wins += reward\n",
    "\n",
    "\n",
    "def mcts(root, num_simulations):\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        # Selection\n",
    "        while node.is_fully_expanded() and node.children:\n",
    "            node = node.best_child()\n",
    "\n",
    "        # Expansion\n",
    "        if not node.is_fully_expanded():\n",
    "            node = node.expand()\n",
    "\n",
    "        # Simulation\n",
    "        total_reward = 0\n",
    "        current_state = node.state\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = current_state.action_space.sample()  # Sample random action\n",
    "            next_state, reward, done, _ = current_state.step(action)  # Step in the environment\n",
    "            total_reward += reward\n",
    "            current_state = next_state\n",
    "\n",
    "        # Backpropagation\n",
    "        while node is not None:\n",
    "            node.update(total_reward)\n",
    "            node = node.parent\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    state, _ = env.reset()  # Unpack the reset return value\n",
    "    root = Node(env)\n",
    "\n",
    "    for episode in range(1000):\n",
    "        state, _ = env.reset()  # Reset the environment\n",
    "        root = Node(env)  # Initialize a new root for each episode\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            mcts(root, num_simulations=100)\n",
    "\n",
    "            # Choose the best action from the root node\n",
    "            best_action = root.best_child(exploration_weight=0).children[0].state.action_space.sample()  # get action based on visits\n",
    "            next_state, reward, done, _ = env.step(best_action)\n",
    "            root = root.best_child()  # move to the best child\n",
    "\n",
    "            if done:\n",
    "                print(f\"Episode {episode} finished!\")\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e796724",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'action_space'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-08527e69e3ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-08527e69e3ab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_simulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Choose the best action from the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-08527e69e3ab>\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(root, num_simulations)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sample random action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Step in the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'action_space'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state  # state of the node\n",
    "        self.parent = parent  # parent node\n",
    "        self.children = []  # child nodes\n",
    "        self.visits = 0  # number of times this node has been visited\n",
    "        self.wins = 0  # total rewards for this node\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) == self.state.action_space.n\n",
    "\n",
    "    def best_child(self, exploration_weight=1.0):\n",
    "        choices_weights = [\n",
    "            (child.wins / child.visits) + exploration_weight * math.sqrt(\n",
    "                (2 * math.log(self.visits) / child.visits) if child.visits > 0 else 0)\n",
    "            for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def expand(self):\n",
    "        unexplored_actions = [a for a in range(self.state.action_space.n) if a not in [child.state.action for child in self.children]]\n",
    "        action = random.choice(unexplored_actions)\n",
    "        next_state, reward, terminated, truncated, _ = self.state.step(action)  # Perform the action\n",
    "        child_node = Node(next_state, parent=self)\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "    def update(self, reward):\n",
    "        self.visits += 1\n",
    "        self.wins += reward\n",
    "\n",
    "\n",
    "def mcts(root, num_simulations):\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        # Selection\n",
    "        while node.is_fully_expanded() and node.children:\n",
    "            node = node.best_child()\n",
    "\n",
    "        # Expansion\n",
    "        if not node.is_fully_expanded():\n",
    "            node = node.expand()\n",
    "\n",
    "        # Simulation\n",
    "        total_reward = 0\n",
    "        current_state = node.state\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = current_state.action_space.sample()  # Sample random action\n",
    "            next_state, reward, terminated, truncated, _ = current_state.step(action)  # Step in the environment\n",
    "            total_reward += reward\n",
    "            current_state = next_state\n",
    "            done = terminated or truncated  # End if either condition is met\n",
    "\n",
    "        # Backpropagation\n",
    "        while node is not None:\n",
    "            node.update(total_reward)\n",
    "            node = node.parent\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    state, _ = env.reset()  # Unpack the reset return value\n",
    "    root = Node(env)\n",
    "\n",
    "    for episode in range(1000):\n",
    "        state, _ = env.reset()  # Reset the environment\n",
    "        root = Node(env)  # Initialize a new root for each episode\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            mcts(root, num_simulations=100)\n",
    "\n",
    "            # Choose the best action from the root node\n",
    "            best_action = root.best_child(exploration_weight=0).children[0].state.action_space.sample()  # get action based on visits\n",
    "            next_state, reward, terminated, truncated, _ = env.step(best_action)\n",
    "            root = root.best_child()  # move to the best child\n",
    "\n",
    "            done = terminated or truncated  # End if either condition is met\n",
    "            if done:\n",
    "                print(f\"Episode {episode} finished!\")\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9e0cb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' on line 19 (<ipython-input-7-602f5a04a113>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-602f5a04a113>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    ]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '(' on line 19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state  # Current state (observation)\n",
    "        self.parent = parent  # Parent node\n",
    "        self.children = []  # Child nodes\n",
    "        self.visits = 0  # Number of visits to this node\n",
    "        self.wins = 0  # Total reward for this node\n",
    "\n",
    "    def is_fully_expanded(self, action_space):\n",
    "        return len(self.children) == action_space.n\n",
    "\n",
    "    def best_child(self, exploration_weight=1.0):\n",
    "        choices_weights = [\n",
    "            (child.wins / child.visits) + exploration_weight * math.sqrt(\n",
    "                (2 * math.log(self.visits) / child.visits) if child.visits > 0 else 0)\n",
    "            for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def expand(self, action_space):\n",
    "        unexplored_actions = [a for a in range(action_space.n) if a not in [child.state[0] for child in self.children]]\n",
    "        action = random.choice(unexplored_actions)\n",
    "        next_state, reward, terminated, truncated, _ = action_space.step(action)  # Perform the action\n",
    "        child_node = Node(next_state, parent=self)\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "    def update(self, reward):\n",
    "        self.visits += 1\n",
    "        self.wins += reward\n",
    "\n",
    "\n",
    "def mcts(root, num_simulations, action_space):\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        # Selection\n",
    "        while node.is_fully_expanded(action_space) and node.children:\n",
    "            node = node.best_child()\n",
    "\n",
    "        # Expansion\n",
    "        if not node.is_fully_expanded(action_space):\n",
    "            node = node.expand(action_space)\n",
    "\n",
    "        # Simulation\n",
    "        total_reward = 0\n",
    "        current_state = node.state\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = action_space.sample()  # Sample random action\n",
    "            next_state, reward, terminated, truncated, _ = action_space.step(action)  # Step in the environment\n",
    "            total_reward += reward\n",
    "            current_state = next_state\n",
    "            done = terminated or truncated  # End if either condition is met\n",
    "\n",
    "        # Backpropagation\n",
    "        while node is not None:\n",
    "            node.update(total_reward)\n",
    "            node = node.parent\n",
    "\n",
    "\n",
    "def main():\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    state, _ = env.reset()  # Unpack the reset return value\n",
    "    root = Node(state)\n",
    "\n",
    "    for episode in range(1000):\n",
    "        state, _ = env.reset()  # Reset the environment\n",
    "        root = Node(state)  # Initialize a new root for each episode\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            mcts(root, num_simulations=100, action_space=env)  # Pass the environment to MCTS\n",
    "\n",
    "            # Choose the best action from the root node\n",
    "            best_child = root.best_child(exploration_weight=0)\n",
    "            best_action = best_child.state[0]  # Get the action based on visits\n",
    "            next_state, reward, terminated, truncated, _ = env.step(best_action)\n",
    "            root = best_child  # Move to the best child\n",
    "\n",
    "            done = terminated or truncated  # End if either condition is met\n",
    "            if done:\n",
    "                print(f\"Episode {episode} finished!\")\n",
    "                break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778725f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e9077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df91be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d75fe26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128f43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de164c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a705029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/n_mbpo/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.state to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.state` for environment variables or `env.get_wrapper_attr('state')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/james/miniconda3/envs/n_mbpo/lib/python3.9/site-packages/gymnasium/envs/classic_control/cartpole.py:180: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 15.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122ae6d0>, <__main__.MCTSNode object at 0x7fce122ae670>]\n",
      "0.0\n",
      "0.0\n",
      "mv 0.0\n",
      "bst 0.0\n",
      "curr 15.0\n",
      "action 0\n",
      "r 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/miniconda3/envs/n_mbpo/lib/python3.9/site-packages/gymnasium/envs/classic_control/cartpole.py:215: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children [<__main__.MCTSNode object at 0x7fce122ae850>, <__main__.MCTSNode object at 0x7fce122ae6a0>]\n",
      "0.0\n",
      "30.0\n",
      "mv 30.0\n",
      "bst 30.0\n",
      "curr 30.0\n",
      "action 1\n",
      "r 17.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122ae640>, <__main__.MCTSNode object at 0x7fce122aeb50>]\n",
      "47.0\n",
      "0.0\n",
      "mv 47.0\n",
      "bst 0.0\n",
      "curr 47.0\n",
      "action 0\n",
      "r 29.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122ae220>, <__main__.MCTSNode object at 0x7fce122aec10>]\n",
      "29.0\n",
      "47.0\n",
      "mv 47.0\n",
      "bst 47.0\n",
      "curr 76.0\n",
      "action 1\n",
      "r 17.0\n",
      "r 21.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122bf040>, <__main__.MCTSNode object at 0x7fce122bf310>]\n",
      "85.0\n",
      "0.0\n",
      "mv 85.0\n",
      "bst 85.0\n",
      "curr 85.0\n",
      "action 0\n",
      "r 9.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122bf5b0>, <__main__.MCTSNode object at 0x7fce122bf640>]\n",
      "55.0\n",
      "39.0\n",
      "mv 55.0\n",
      "bst 39.0\n",
      "curr 94.0\n",
      "action 0\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122bfbb0>, <__main__.MCTSNode object at 0x7fce122bfc40>]\n",
      "28.0\n",
      "34.0\n",
      "mv 34.0\n",
      "bst 28.0\n",
      "curr 62.0\n",
      "action 1\n",
      "r 11.0\n",
      "children [<__main__.MCTSNode object at 0x7fce12289b20>, <__main__.MCTSNode object at 0x7fce12289bb0>]\n",
      "0.0\n",
      "45.0\n",
      "mv 45.0\n",
      "bst 0.0\n",
      "curr 45.0\n",
      "action 1\n",
      "r 6.0\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7fce121e75b0>, <__main__.MCTSNode object at 0x7fce121e7640>]\n",
      "51.0\n",
      "4.0\n",
      "mv 51.0\n",
      "bst 51.0\n",
      "curr 55.0\n",
      "action 0\n",
      "r 9.0\n",
      "children [<__main__.MCTSNode object at 0x7fce12206670>, <__main__.MCTSNode object at 0x7fce12206700>]\n",
      "6.0\n",
      "54.0\n",
      "mv 54.0\n",
      "bst 54.0\n",
      "curr 60.0\n",
      "action 1\n",
      "r 26.0\n",
      "children [<__main__.MCTSNode object at 0x7fce12179340>, <__main__.MCTSNode object at 0x7fce12179520>]\n",
      "37.0\n",
      "43.0\n",
      "mv 43.0\n",
      "bst 37.0\n",
      "curr 80.0\n",
      "action 1\n",
      "r 27.0\n",
      "r 20.0\n",
      "children [<__main__.MCTSNode object at 0x7fce120c9820>, <__main__.MCTSNode object at 0x7fce121d09d0>]\n",
      "73.0\n",
      "0.0\n",
      "mv 73.0\n",
      "bst 73.0\n",
      "curr 90.0\n",
      "action 0\n",
      "r 11.0\n",
      "r 3.0\n",
      "children [<__main__.MCTSNode object at 0x7fce122ae4c0>, <__main__.MCTSNode object at 0x7fce120bcfa0>]\n",
      "37.0\n",
      "50.0\n",
      "mv 50.0\n",
      "bst 50.0\n",
      "curr 87.0\n",
      "action 1\n",
      "r 10.0\n",
      "children [<__main__.MCTSNode object at 0x7fce120c9910>, <__main__.MCTSNode object at 0x7fce121d0d90>]\n",
      "3.0\n",
      "57.0\n",
      "mv 57.0\n",
      "bst 57.0\n",
      "curr 60.0\n",
      "action 1\n",
      "r 15.0\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7fce120c99d0>, <__main__.MCTSNode object at 0x7fce120c9a90>]\n",
      "19.0\n",
      "57.0\n",
      "mv 57.0\n",
      "bst 57.0\n",
      "curr 76.0\n",
      "action 1\n",
      "r 16.0\n",
      "children [<__main__.MCTSNode object at 0x7fce12084c70>, <__main__.MCTSNode object at 0x7fce12084be0>]\n",
      "47.0\n",
      "26.0\n",
      "mv 47.0\n",
      "bst 47.0\n",
      "curr 73.0\n",
      "action 0\n",
      "r 8.0\n",
      "children [<__main__.MCTSNode object at 0x7fce11fa9730>, <__main__.MCTSNode object at 0x7fce11fa97c0>]\n",
      "55.0\n",
      "0.0\n",
      "mv 55.0\n",
      "bst 55.0\n",
      "curr 55.0\n",
      "action 0\n",
      "r 73.0\n",
      "children [<__main__.MCTSNode object at 0x7fce11ec1280>, <__main__.MCTSNode object at 0x7fce11ec1520>]\n",
      "120.0\n",
      "8.0\n",
      "mv 120.0\n",
      "bst 120.0\n",
      "curr 128.0\n",
      "action 0\n",
      "r 8.0\n",
      "children [<__main__.MCTSNode object at 0x7fce11d2fb20>, <__main__.MCTSNode object at 0x7fce11d2fbb0>]\n",
      "0.0\n",
      "128.0\n",
      "mv 128.0\n",
      "bst 128.0\n",
      "curr 128.0\n",
      "action 1\n",
      "r 8.0\n",
      "children [<__main__.MCTSNode object at 0x7fce1196c760>, <__main__.MCTSNode object at 0x7fce1196c7f0>]\n",
      "81.0\n",
      "55.0\n",
      "mv 81.0\n",
      "bst 81.0\n",
      "curr 136.0\n",
      "action 0\n",
      "r 5.0\n",
      "children [<__main__.MCTSNode object at 0x7fce1195b430>, <__main__.MCTSNode object at 0x7fce1195bf10>]\n",
      "5.0\n",
      "81.0\n",
      "mv 81.0\n",
      "bst 5.0\n",
      "curr 86.0\n",
      "action 1\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7fce117ff310>, <__main__.MCTSNode object at 0x7fce117ff190>]\n",
      "88.0\n",
      "0.0\n",
      "mv 88.0\n",
      "bst 0.0\n",
      "curr 88.0\n",
      "action 0\n",
      "r 5.0\n",
      "children [<__main__.MCTSNode object at 0x7fce117ff760>, <__main__.MCTSNode object at 0x7fce117ff7f0>]\n",
      "78.0\n",
      "15.0\n",
      "mv 78.0\n",
      "bst 15.0\n",
      "curr 93.0\n",
      "action 0\n",
      "r 3.0\n",
      "children [<__main__.MCTSNode object at 0x7fce117ffeb0>, <__main__.MCTSNode object at 0x7fce117ff2b0>]\n",
      "3.0\n",
      "78.0\n",
      "mv 78.0\n",
      "bst 3.0\n",
      "curr 81.0\n",
      "action 1\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7fce11673df0>, <__main__.MCTSNode object at 0x7fce11673e80>]\n",
      "0.0\n",
      "82.0\n",
      "mv 82.0\n",
      "bst 82.0\n",
      "curr 82.0\n",
      "action 1\n",
      "r 3.0\n",
      "r 4.0\n",
      "children [<__main__.MCTSNode object at 0x7fce1148f6a0>, <__main__.MCTSNode object at 0x7fce1148f730>]\n",
      "7.0\n",
      "82.0\n",
      "mv 82.0\n",
      "bst 82.0\n",
      "curr 89.0\n",
      "action 1\n",
      "r 2.0\n",
      "r 5.0\n",
      "children [<__main__.MCTSNode object at 0x7fce112d43a0>, <__main__.MCTSNode object at 0x7fce112d44f0>]\n",
      "89.0\n",
      "0.0\n",
      "mv 89.0\n",
      "bst 0.0\n",
      "curr 89.0\n",
      "action 0\n",
      "r 1.0\n",
      "r 7.0\n",
      "children [<__main__.MCTSNode object at 0x7fce1133ca90>, <__main__.MCTSNode object at 0x7fce115e2640>]\n",
      "16.0\n",
      "8.0\n",
      "mv 16.0\n",
      "bst 16.0\n",
      "curr 97.0\n",
      "action 0\n",
      "done\n",
      "28.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import animation\n",
    "\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None, action=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.action = action\n",
    "        self.visits = 0\n",
    "        self.wins = 0\n",
    "\n",
    "    def is_fully_expanded(self, action_space_size):\n",
    "        return len(self.children) == action_space_size\n",
    "\n",
    "    def best_child(self, exploration_param=1.414):\n",
    "        choices_weights = [\n",
    "            (child.wins / max(1, child.visits)) + exploration_param * math.sqrt(\n",
    "                math.log(max(1, self.visits)) / max(1, child.visits)\n",
    "            ) for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def most_visited_child(self):\n",
    "        return max(self.children, key=lambda child: child.visits)\n",
    "\n",
    "def discretize_state(state, bins):\n",
    "    \"\"\"\n",
    "    Discretize the continuous state into a discrete bin representation.\n",
    "    We create bins for each feature (position, velocity, angle, angular velocity).\n",
    "    \"\"\"\n",
    "    binned_state = []\n",
    "    for i in range(len(state)):\n",
    "#         print('state[i]', state[i])\n",
    "#         print('bin[i]', bins[i])\n",
    "        binned_state.append(np.digitize(state[i], bins[i]))\n",
    "    return tuple(binned_state)\n",
    "\n",
    "def create_bins():\n",
    "    \"\"\"\n",
    "    Create bins for each state variable.\n",
    "    CartPole has 4 continuous state variables:\n",
    "    [Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity].\n",
    "    We define the ranges and bins for each.\n",
    "    \"\"\"\n",
    "    bins = [\n",
    "        np.linspace(-4.8, 4.8, 10),  # Cart Position\n",
    "        np.linspace(-5.0, 5.0, 10),  # Cart Velocity\n",
    "        np.linspace(-0.418, 0.418, 10),  # Pole Angle\n",
    "        np.linspace(-5.0, 5.0, 10),  # Pole Angular Velocity\n",
    "    ]\n",
    "    return bins\n",
    "\n",
    "def rollout(env, bins):\n",
    "    \"\"\"\n",
    "    Simulate a random rollout from the current state.\n",
    "    \"\"\"\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Randomly pick an action (exploration)\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def backpropagate(node, reward):\n",
    "    while node is not None:\n",
    "        node.visits += 1\n",
    "        node.wins += reward\n",
    "        node = node.parent\n",
    "\n",
    "def expand(node, env, action_space_size, bins):\n",
    "    \"\"\"\n",
    "    Expand the node by creating child nodes for each action.\n",
    "    \"\"\"\n",
    "    for action in range(action_space_size):\n",
    "        # Clone the environment and step with the current action\n",
    "        env_copy = gym.make('CartPole-v1')\n",
    "        env_copy.reset()\n",
    "        env_copy.env.state = env.env.state  # Copy the environment state\n",
    "        state, reward, done, _, _ = env_copy.step(action)\n",
    "\n",
    "        # Discretize the state to get the discrete representation\n",
    "        discrete_state = discretize_state(state, bins)\n",
    "\n",
    "        child_node = MCTSNode(state=discrete_state, parent=node, action=action)\n",
    "        node.children.append(child_node)\n",
    "\n",
    "def select(node, action_space_size):\n",
    "    \"\"\"\n",
    "    Traverse the tree by selecting the best child node based on the UCB1 algorithm.\n",
    "    \"\"\"\n",
    "    current_node = node\n",
    "    while current_node.is_fully_expanded(action_space_size):\n",
    "        current_node = current_node.best_child()\n",
    "    return current_node\n",
    "\n",
    "def mcts(env, state, current_node, simulations=1000):\n",
    "    env_copy = copy.deepcopy(env)\n",
    "    action_space_size = env.action_space.n\n",
    "\n",
    "    for _ in range(simulations):\n",
    "        # Step 1: Selection\n",
    "        selected_node = select(current_node, action_space_size)\n",
    "#         print('sn',selected_node)\n",
    "        \n",
    "        # Step 2: Expansion\n",
    "        expand(selected_node, env_copy, action_space_size, bins)\n",
    "        \n",
    "        # Step 3: Simulation\n",
    "        reward = rollout(env_copy, bins)\n",
    "        if reward !=0:\n",
    "            print('r', reward)\n",
    "        \n",
    "        # Step 4: Backpropagation\n",
    "        backpropagate(selected_node, reward)\n",
    "        \n",
    "    best_node = current_node.best_child(exploration_param=0)\n",
    "    print('children', current_node.children)\n",
    "    for c in current_node.children:\n",
    "        print(c.wins)\n",
    "    print('mv', current_node.most_visited_child().wins)\n",
    "    print('bst', current_node.best_child().wins)\n",
    "    print('curr', current_node.wins)\n",
    "    return best_node\n",
    "\n",
    "# Initialize the CartPole environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Run MCTS for 1000 simulations\n",
    "\n",
    "\n",
    "# Apply the best move (select action based on the best child)\n",
    "env.reset()\n",
    "done = False\n",
    "tot_r = 0\n",
    "\n",
    "# Discretize the initial state\n",
    "bins = create_bins()\n",
    "discrete_state = discretize_state(state, bins)\n",
    "current_node = MCTSNode(discrete_state) # first will be root node\n",
    "\n",
    "while not done:\n",
    "    current_node = mcts(env, state, current_node, simulations=1000)\n",
    "    print('action', current_node.action)\n",
    "    state, reward, done, _, _ = env.step(current_node.action)\n",
    "    tot_r += reward\n",
    "    #     print(reward)\n",
    "    env.render()\n",
    "\n",
    "print('done')\n",
    "print(tot_r)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2401b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8ddcf94",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'pygame.surface.Surface' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-967201aafeaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mcurrent_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mtot_r\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-967201aafeaf>\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(env, state, current_node, simulations)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0menv_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0maction_space_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/n_mbpo/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreductor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                         \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'pygame.surface.Surface' object"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import animation\n",
    "from gym.wrappers import RecordVideo\n",
    "from IPython.display import Video\n",
    "import cv2\n",
    "\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None, action=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.action = action\n",
    "        self.visits = 0\n",
    "        self.wins = 0\n",
    "\n",
    "    def is_fully_expanded(self, action_space_size):\n",
    "        return len(self.children) == action_space_size\n",
    "\n",
    "    def best_child(self, exploration_param=1.414):\n",
    "        choices_weights = [\n",
    "            (child.wins / max(1, child.visits)) + exploration_param * math.sqrt(\n",
    "                math.log(max(1, self.visits)) / max(1, child.visits)\n",
    "            ) for child in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "    def most_visited_child(self):\n",
    "        return max(self.children, key=lambda child: child.visits)\n",
    "\n",
    "def discretize_state(state, bins):\n",
    "    \"\"\"\n",
    "    Discretize the continuous state into a discrete bin representation.\n",
    "    We create bins for each feature (position, velocity, angle, angular velocity).\n",
    "    \"\"\"\n",
    "    binned_state = []\n",
    "    for i in range(len(state)):\n",
    "        binned_state.append(np.digitize(state[i], bins[i]))\n",
    "    return tuple(binned_state)\n",
    "\n",
    "def create_bins():\n",
    "    \"\"\"\n",
    "    Create bins for each state variable.\n",
    "    CartPole has 4 continuous state variables:\n",
    "    [Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity].\n",
    "    We define the ranges and bins for each.\n",
    "    \"\"\"\n",
    "    bins = [\n",
    "        np.linspace(-4.8, 4.8, 10),  # Cart Position\n",
    "        np.linspace(-5.0, 5.0, 10),  # Cart Velocity\n",
    "        np.linspace(-0.418, 0.418, 10),  # Pole Angle\n",
    "        np.linspace(-5.0, 5.0, 10),  # Pole Angular Velocity\n",
    "    ]\n",
    "    return bins\n",
    "\n",
    "def rollout(env, bins):\n",
    "    \"\"\"\n",
    "    Simulate a random rollout from the current state.\n",
    "    \"\"\"\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Randomly pick an action (exploration)\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def backpropagate(node, reward):\n",
    "    while node is not None:\n",
    "        node.visits += 1\n",
    "        node.wins += reward\n",
    "        node = node.parent\n",
    "\n",
    "def expand(node, env, action_space_size, bins):\n",
    "    \"\"\"\n",
    "    Expand the node by creating child nodes for each action.\n",
    "    \"\"\"\n",
    "    for action in range(action_space_size):\n",
    "        # Clone the environment and step with the current action\n",
    "        env_copy = gym.make('CartPole-v1')\n",
    "        env_copy.reset()\n",
    "        env_copy.env.state = env.env.state  # Copy the environment state\n",
    "        state, reward, done, _, _ = env_copy.step(action)\n",
    "\n",
    "        # Discretize the state to get the discrete representation\n",
    "        discrete_state = discretize_state(state, bins)\n",
    "\n",
    "        child_node = MCTSNode(state=discrete_state, parent=node, action=action)\n",
    "        node.children.append(child_node)\n",
    "\n",
    "def select(node, action_space_size):\n",
    "    \"\"\"\n",
    "    Traverse the tree by selecting the best child node based on the UCB1 algorithm.\n",
    "    \"\"\"\n",
    "    current_node = node\n",
    "    while current_node.is_fully_expanded(action_space_size):\n",
    "        current_node = current_node.best_child()\n",
    "    return current_node\n",
    "\n",
    "def mcts(env, state, current_node, simulations=1000):\n",
    "    env_copy = copy.deepcopy(env)\n",
    "    action_space_size = env.action_space.n\n",
    "\n",
    "    for _ in range(simulations):\n",
    "        # Step 1: Selection\n",
    "        selected_node = select(current_node, action_space_size)\n",
    "#         print('sn',selected_node)\n",
    "        \n",
    "        # Step 2: Expansion\n",
    "        expand(selected_node, env_copy, action_space_size, bins)\n",
    "        \n",
    "        # Step 3: Simulation\n",
    "        reward = rollout(env_copy, bins)\n",
    "        if reward !=0:\n",
    "            print('r', reward)\n",
    "        \n",
    "        # Step 4: Backpropagation\n",
    "        backpropagate(selected_node, reward)\n",
    "        \n",
    "    best_node = current_node.best_child(exploration_param=0)\n",
    "    return best_node\n",
    "\n",
    "def show_frame(frame):\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Initialize the CartPole environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "# Define video recording parameters\n",
    "video_path = 'cartpole_mcts.mp4'\n",
    "frame_width = env.render().shape[1]\n",
    "frame_height = env.render().shape[0]\n",
    "fps = 30  # Set the frames per second\n",
    "\n",
    "# Create a video writer object using OpenCV\n",
    "video_writer = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply the best move (select action based on the best child)\n",
    "env.reset()\n",
    "done = False\n",
    "tot_r = 0\n",
    "\n",
    "# Discretize the initial state\n",
    "bins = create_bins()\n",
    "discrete_state = discretize_state(state, bins)\n",
    "current_node = MCTSNode(discrete_state) # first will be root node\n",
    "\n",
    "while not done:\n",
    "    current_node = mcts(env, state, current_node, simulations=1000)\n",
    "    state, reward, done, _, _ = env.step(1)\n",
    "    tot_r += reward\n",
    "\n",
    "\n",
    "\n",
    "print('done')\n",
    "print(tot_r)\n",
    "env.close()\n",
    "\n",
    "\n",
    "# Release the video writer\n",
    "video_writer.release()\n",
    "\n",
    "# Display the recorded video in the notebook\n",
    "Video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50d2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:n_mbpo] *",
   "language": "python",
   "name": "conda-env-n_mbpo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
